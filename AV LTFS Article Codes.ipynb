{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime as dt\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Data \n",
    "train=pd.read_csv(\"D://LTFS//train.csv\")\n",
    "test=pd.read_csv(\"D://LTFS//test_bqCt9Pv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniqueID</th>\n",
       "      <th>disbursed_amount</th>\n",
       "      <th>asset_cost</th>\n",
       "      <th>ltv</th>\n",
       "      <th>branch_id</th>\n",
       "      <th>supplier_id</th>\n",
       "      <th>manufacturer_id</th>\n",
       "      <th>Current_pincode_ID</th>\n",
       "      <th>Date.of.Birth</th>\n",
       "      <th>Employment.Type</th>\n",
       "      <th>...</th>\n",
       "      <th>SEC.SANCTIONED.AMOUNT</th>\n",
       "      <th>SEC.DISBURSED.AMOUNT</th>\n",
       "      <th>PRIMARY.INSTAL.AMT</th>\n",
       "      <th>SEC.INSTAL.AMT</th>\n",
       "      <th>NEW.ACCTS.IN.LAST.SIX.MONTHS</th>\n",
       "      <th>DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS</th>\n",
       "      <th>AVERAGE.ACCT.AGE</th>\n",
       "      <th>CREDIT.HISTORY.LENGTH</th>\n",
       "      <th>NO.OF_INQUIRIES</th>\n",
       "      <th>loan_default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>420825</td>\n",
       "      <td>50578</td>\n",
       "      <td>58400</td>\n",
       "      <td>89.55</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1441</td>\n",
       "      <td>01-01-84</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>537409</td>\n",
       "      <td>47145</td>\n",
       "      <td>65550</td>\n",
       "      <td>73.23</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1502</td>\n",
       "      <td>31-07-85</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1991</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1yrs 11mon</td>\n",
       "      <td>1yrs 11mon</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>417566</td>\n",
       "      <td>53278</td>\n",
       "      <td>61360</td>\n",
       "      <td>89.63</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1497</td>\n",
       "      <td>24-08-85</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>624493</td>\n",
       "      <td>57513</td>\n",
       "      <td>66113</td>\n",
       "      <td>88.48</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1501</td>\n",
       "      <td>30-12-93</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0yrs 8mon</td>\n",
       "      <td>1yrs 3mon</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539055</td>\n",
       "      <td>52378</td>\n",
       "      <td>60300</td>\n",
       "      <td>88.39</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1495</td>\n",
       "      <td>09-12-77</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UniqueID  disbursed_amount  asset_cost    ltv  branch_id  supplier_id  \\\n",
       "0    420825             50578       58400  89.55         67        22807   \n",
       "1    537409             47145       65550  73.23         67        22807   \n",
       "2    417566             53278       61360  89.63         67        22807   \n",
       "3    624493             57513       66113  88.48         67        22807   \n",
       "4    539055             52378       60300  88.39         67        22807   \n",
       "\n",
       "   manufacturer_id  Current_pincode_ID Date.of.Birth Employment.Type  \\\n",
       "0               45                1441      01-01-84        Salaried   \n",
       "1               45                1502      31-07-85   Self employed   \n",
       "2               45                1497      24-08-85   Self employed   \n",
       "3               45                1501      30-12-93   Self employed   \n",
       "4               45                1495      09-12-77   Self employed   \n",
       "\n",
       "       ...      SEC.SANCTIONED.AMOUNT  SEC.DISBURSED.AMOUNT  \\\n",
       "0      ...                          0                     0   \n",
       "1      ...                          0                     0   \n",
       "2      ...                          0                     0   \n",
       "3      ...                          0                     0   \n",
       "4      ...                          0                     0   \n",
       "\n",
       "   PRIMARY.INSTAL.AMT  SEC.INSTAL.AMT  NEW.ACCTS.IN.LAST.SIX.MONTHS  \\\n",
       "0                   0               0                             0   \n",
       "1                1991               0                             0   \n",
       "2                   0               0                             0   \n",
       "3                  31               0                             0   \n",
       "4                   0               0                             0   \n",
       "\n",
       "   DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS  AVERAGE.ACCT.AGE  \\\n",
       "0                                    0         0yrs 0mon   \n",
       "1                                    1        1yrs 11mon   \n",
       "2                                    0         0yrs 0mon   \n",
       "3                                    0         0yrs 8mon   \n",
       "4                                    0         0yrs 0mon   \n",
       "\n",
       "   CREDIT.HISTORY.LENGTH  NO.OF_INQUIRIES  loan_default  \n",
       "0              0yrs 0mon                0             0  \n",
       "1             1yrs 11mon                0             1  \n",
       "2              0yrs 0mon                0             0  \n",
       "3              1yrs 3mon                1             1  \n",
       "4              0yrs 0mon                1             1  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniqueID</th>\n",
       "      <th>disbursed_amount</th>\n",
       "      <th>asset_cost</th>\n",
       "      <th>ltv</th>\n",
       "      <th>branch_id</th>\n",
       "      <th>supplier_id</th>\n",
       "      <th>manufacturer_id</th>\n",
       "      <th>Current_pincode_ID</th>\n",
       "      <th>Date.of.Birth</th>\n",
       "      <th>Employment.Type</th>\n",
       "      <th>...</th>\n",
       "      <th>SEC.CURRENT.BALANCE</th>\n",
       "      <th>SEC.SANCTIONED.AMOUNT</th>\n",
       "      <th>SEC.DISBURSED.AMOUNT</th>\n",
       "      <th>PRIMARY.INSTAL.AMT</th>\n",
       "      <th>SEC.INSTAL.AMT</th>\n",
       "      <th>NEW.ACCTS.IN.LAST.SIX.MONTHS</th>\n",
       "      <th>DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS</th>\n",
       "      <th>AVERAGE.ACCT.AGE</th>\n",
       "      <th>CREDIT.HISTORY.LENGTH</th>\n",
       "      <th>NO.OF_INQUIRIES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>655269</td>\n",
       "      <td>53478</td>\n",
       "      <td>63558</td>\n",
       "      <td>86.54</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1497</td>\n",
       "      <td>01-01-74</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>723482</td>\n",
       "      <td>55513</td>\n",
       "      <td>63163</td>\n",
       "      <td>89.45</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1497</td>\n",
       "      <td>20-05-85</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0yrs 8mon</td>\n",
       "      <td>1yrs 0mon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>758529</td>\n",
       "      <td>65282</td>\n",
       "      <td>84320</td>\n",
       "      <td>79.93</td>\n",
       "      <td>78</td>\n",
       "      <td>23135</td>\n",
       "      <td>86</td>\n",
       "      <td>2071</td>\n",
       "      <td>14-10-95</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>763449</td>\n",
       "      <td>46905</td>\n",
       "      <td>63896</td>\n",
       "      <td>76.58</td>\n",
       "      <td>78</td>\n",
       "      <td>17014</td>\n",
       "      <td>45</td>\n",
       "      <td>2070</td>\n",
       "      <td>01-06-73</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2yrs 5mon</td>\n",
       "      <td>2yrs 5mon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>708663</td>\n",
       "      <td>51428</td>\n",
       "      <td>63896</td>\n",
       "      <td>86.08</td>\n",
       "      <td>78</td>\n",
       "      <td>17014</td>\n",
       "      <td>45</td>\n",
       "      <td>2069</td>\n",
       "      <td>01-06-72</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UniqueID  disbursed_amount  asset_cost    ltv  branch_id  supplier_id  \\\n",
       "0    655269             53478       63558  86.54         67        22807   \n",
       "1    723482             55513       63163  89.45         67        22807   \n",
       "2    758529             65282       84320  79.93         78        23135   \n",
       "3    763449             46905       63896  76.58         78        17014   \n",
       "4    708663             51428       63896  86.08         78        17014   \n",
       "\n",
       "   manufacturer_id  Current_pincode_ID Date.of.Birth Employment.Type  \\\n",
       "0               45                1497      01-01-74        Salaried   \n",
       "1               45                1497      20-05-85   Self employed   \n",
       "2               86                2071      14-10-95        Salaried   \n",
       "3               45                2070      01-06-73   Self employed   \n",
       "4               45                2069      01-06-72        Salaried   \n",
       "\n",
       "        ...        SEC.CURRENT.BALANCE  SEC.SANCTIONED.AMOUNT  \\\n",
       "0       ...                          0                      0   \n",
       "1       ...                          0                      0   \n",
       "2       ...                          0                      0   \n",
       "3       ...                          0                      0   \n",
       "4       ...                          0                      0   \n",
       "\n",
       "   SEC.DISBURSED.AMOUNT  PRIMARY.INSTAL.AMT  SEC.INSTAL.AMT  \\\n",
       "0                     0                   0               0   \n",
       "1                     0                5605               0   \n",
       "2                     0                   0               0   \n",
       "3                     0                   0               0   \n",
       "4                     0                   0               0   \n",
       "\n",
       "   NEW.ACCTS.IN.LAST.SIX.MONTHS  DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS  \\\n",
       "0                             0                                    0   \n",
       "1                             1                                    0   \n",
       "2                             0                                    0   \n",
       "3                             0                                    0   \n",
       "4                             0                                    0   \n",
       "\n",
       "   AVERAGE.ACCT.AGE  CREDIT.HISTORY.LENGTH  NO.OF_INQUIRIES  \n",
       "0         0yrs 0mon              0yrs 0mon                0  \n",
       "1         0yrs 8mon              1yrs 0mon                1  \n",
       "2         0yrs 0mon              0yrs 0mon                0  \n",
       "3         2yrs 5mon              2yrs 5mon                0  \n",
       "4         0yrs 0mon              0yrs 0mon                0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method 1\n",
    "def calculateage(v):\n",
    "    return pd.to_datetime('today').year-pd.to_datetime(v).year\n",
    "def d(v):\n",
    "    if v.split(\"-\")[-1]=='00' or v.split(\"-\")[-1]=='18':\n",
    "        return \"-\".join(v.split(\"-\")[:-1])+'-20'+\"\".join(v.split(\"-\")[-1])\n",
    "    else:\n",
    "        return \"-\".join(v.split(\"-\")[:-1])+'-19'+\"\".join(v.split(\"-\")[-1])\n",
    "train['Date.of.Birth']=pd.to_datetime(train['Date.of.Birth'].apply(d),format='%d-%m-%Y',errors='coerce')\n",
    "train['age']=train['Date.of.Birth'].apply(calculateage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method 2\n",
    "def calcAge(x):\n",
    "    year = int(x.split('-')[2])\n",
    "    if(year<=19):\n",
    "        age = 20-year\n",
    "    else:\n",
    "        age = 100 + (20-year)\n",
    "    return age\n",
    "train['Age']=train['Date.of.Birth'].apply(calcAge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method 3\n",
    "train['Date.of.Birth'] = np.where(train['Date.of.Birth'].dt.year < 2010\n",
    "                                     ,train['Date.of.Birth']\n",
    "                                     ,train['Date.of.Birth'] - pd.DateOffset(years=100)\n",
    "                                    )\n",
    "train['customer_age'] = round((train['DisbursalDate'] - train['Date.of.Birth']).dt.days / 365.2425)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method 4\n",
    "def format_date(col):\n",
    "    temp = []\n",
    "    for x in pd.to_datetime(col, format=\"%d-%m-%y\"):\n",
    "        if x > pd.to_datetime('today'):    temp.append(x - pd.DateOffset(years=100))\n",
    "        else:                              temp.append(x)\n",
    "    return temp\n",
    "train['Date.of.Birth']  =  format_date(train['Date.of.Birth'])\n",
    "train['Age__at_loan_disbursal']  =  train['DisbursalDate'] - train['Date.of.Birth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method 5\n",
    "train['Date.of.Birth']=train['Date.of.Birth'].astype('datetime64[ns]')\n",
    "a=train['Date.of.Birth'].dt.year.apply(lambda x: x if x<2018 else x-100).values\n",
    "b=train['Date.of.Birth'].dt.month.values\n",
    "c=train['Date.of.Birth'].dt.day.values\n",
    "train['Date.of.Birth']=pd.to_datetime(dict(year=a,month=b,day=c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disbursal Date and Date of Birth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method 1\n",
    "train['DOB_day']    =  train['Date.of.Birth'].dt.day\n",
    "train['DOB_month']  =  train['Date.of.Birth'].dt.month\n",
    "train['DOB_year']   =  train['Date.of.Birth'].dt.year\n",
    "train['DOB_dayofweek']   =  train['Date.of.Birth'].dt.dayofweek\n",
    "train['Date.of.Birth_quarter'] = train['Date.of.Birth'].dt.quarter\n",
    "\n",
    "train['DisbursalDate_day']    =  train['DisbursalDate'].dt.day\n",
    "train['DisbursalDate_month']  =  train['DisbursalDate'].dt.month\n",
    "train['DisbursalDate_year']   =  train['DisbursalDate'].dt.year\n",
    "train['DisbursalDate_dayofweek']   =  train['DisbursalDate'].dt.dayofweek\n",
    "train['DisbursalDate_quarter'] = train['DisbursalDate'].dt.quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method 2 \n",
    "def get_time_of_month_cat(date):\n",
    "    if int(date) < 10:\n",
    "        time_of_month = 'Beginning'\n",
    "    elif int(date) >= 10 and int(date) < 20:\n",
    "        time_of_month = 'Middle'\n",
    "    else:\n",
    "        time_of_month = 'End'\n",
    "    return time_of_month\n",
    "def get_end_of_month(date):\n",
    "    if int(date) >= 25:\n",
    "        end_of_month = 1\n",
    "    else:\n",
    "        end_of_month = 0\n",
    "    return end_of_month\n",
    "def datedata(df,col):\n",
    "    import datetime as dt\n",
    "    df[col]=df[col].astype('datetime64[ns]')\n",
    "    df['year'] = df[col].dt.year\n",
    "    df['month'] = df[col].dt.month\n",
    "    df['date'] = df[col].dt.day\n",
    "    week=[\"Monday\",\"Tuesday\",\"Wednesday\",\"Thrusday\",\"Friday\",\"Saturday\",\"Sunday\"]\n",
    "    df['day'] = df[col].apply(lambda x: week[x.weekday()])\n",
    "    y=dt.datetime(df[col].min().year,df[col].min().month,df[col].min().day)\n",
    "    df['Abs_Dt']=df[col].apply(lambda x: (x-y).days)\n",
    "    df['week_no']=df[col].dt.week\n",
    "    df['Time_of_Month']=df['date'].apply(lambda x: get_time_of_month_cat(x))\n",
    "    df['end_of_month']=df['date'].apply(lambda x: get_end_of_month(x))\n",
    "    df['quarter']=df[col].dt.quarter\n",
    "    df.rename(columns={'year':col+'_year','month':col+'_month','date':col+'_date','day':col+'_day','Abs_Dt':col+'_Abs_Dt','week_no':col+'_week_no','Time_of_Month':col+'_Time_of_Month','end_of_month':col+'_end_of_month','quarter':col+'_quarter'},inplace=True)\n",
    "    df.drop(col,axis=1,inplace=True)\n",
    "    return df\n",
    "train=datedata(train,'Date.of.Birth')\n",
    "train=datedata(train,'DisbursalDate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credit History Length and Average Account Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method 1\n",
    "train['AVERAGE.ACCT.AGE_year']=train['AVERAGE.ACCT.AGE'].apply(lambda x:re.match(r'([0-9]+)yrs ([0-9]+)mon',x).group(1))\n",
    "train['AVERAGE.ACCT.AGE_month']=train['AVERAGE.ACCT.AGE'].apply(lambda x:re.match(r'([0-9]+)yrs ([0-9]+)mon',x).group(2))\n",
    "train['AVERAGE.ACCT.AGE_year']=train['AVERAGE.ACCT.AGE_year'].astype(int)\n",
    "train['AVERAGE.ACCT.AGE_month']=train['AVERAGE.ACCT.AGE_month'].astype(int)\n",
    "train['AVERAGE.ACCT.AGE_total_in_month']=(train['AVERAGE.ACCT.AGE_month']+12*train['AVERAGE.ACCT.AGE_year'])\n",
    "\n",
    "train['CREDIT.HISTORY.LENGTH_year']=train['CREDIT.HISTORY.LENGTH'].apply(lambda x:re.match(r'([0-9]+)yrs ([0-9]+)mon',x).group(1))\n",
    "train['CREDIT.HISTORY.LENGTH_month']=train['CREDIT.HISTORY.LENGTH'].apply(lambda x:re.match(r'([0-9]+)yrs ([0-9]+)mon',x).group(2))\n",
    "train['CREDIT.HISTORY.LENGTH_year']=train['CREDIT.HISTORY.LENGTH_year'].astype(int)\n",
    "train['CREDIT.HISTORY.LENGTH_month']=train['CREDIT.HISTORY.LENGTH_month'].astype(int)\n",
    "train['CREDIT.HISTORY.LENGTH_total_in_month']=train['CREDIT.HISTORY.LENGTH_month']*12+train['CREDIT.HISTORY.LENGTH_year']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method 2 \n",
    "train['acct_age']=train['AVERAGE.ACCT.AGE'].apply(lambda x: int(x.split(\" \")[0][:-3])*12+int(x.split(\" \")[1][:-3]))\n",
    "train['AVERAGE.ACCT.AGE.YEAR']=train['AVERAGE.ACCT.AGE'].apply(lambda x: int(x.split(\" \")[0][:-3]))\n",
    "train['AVERAGE.ACCT.AGE.MONTH']=train['AVERAGE.ACCT.AGE'].apply(lambda x: int(x.split(\" \")[1][:-3]))\n",
    "\n",
    "train['credit_history_len']=train['CREDIT.HISTORY.LENGTH'].apply(lambda x: int(x.split(\" \")[0][:-3])*12+int(x.split(\" \")[1][:-3]))\n",
    "train['CREDIT.HISTORY.LENGTH.YEAR']=train['CREDIT.HISTORY.LENGTH'].apply(lambda x: int(x.split(\" \")[0][:-3]))\n",
    "train['CREDIT.HISTORY.LENGTH.MONTH']=train['CREDIT.HISTORY.LENGTH'].apply(lambda x: int(x.split(\" \")[1][:-3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method 3\n",
    "def AvgAcctAge(x):\n",
    "    year = int(x.split(\" \")[0].split(\"y\")[0])\n",
    "    month = int(x.split(\" \")[1].split(\"m\")[0])\n",
    "    time_int = (12*year) + month\n",
    "    return time_int\n",
    "\n",
    "train[\"AvgAcctAge\"] = train['AVERAGE.ACCT.AGE'].apply(AvgAcctAge)\n",
    "train['CredAcctAge'] = train['CREDIT.HISTORY.LENGTH'].apply(AvgAcctAge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method 4\n",
    "def get_num_months(x):\n",
    "    x = str(x).split()\n",
    "    yr = int(x[0].replace(\"yrs\",\"\"))\n",
    "    mnth = int(x[1].replace(\"mon\",\"\"))\n",
    "    return ((yr*12) + mnth)\n",
    "\n",
    "for col in [\"AVERAGE.ACCT.AGE\", \"CREDIT.HISTORY.LENGTH\"]:\n",
    "    train_df[col] = train_df[col].apply(lambda x: get_num_months(x))\n",
    "    test_df[col] = test_df[col].apply(lambda x: get_num_months(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method 5\n",
    "df['AVERAGE.ACCT.AGE'] = pd.to_numeric(df['AVERAGE.ACCT.AGE'].str.replace(r'(\\d+).*(\\d+).*', lambda x: '{}.{:0>2}'.format(x[1], x[2])), errors='coerce')\n",
    "df['AVERAGE.ACCT.AGE'] = df['AVERAGE.ACCT.AGE'].apply(lambda x: (math.modf(x)[0]*6)+math.modf(x)[1])\n",
    "df['CREDIT.HISTORY.LENGTH'] = pd.to_numeric(df['CREDIT.HISTORY.LENGTH'].str.replace(r'(\\d+).*(\\d+).*', lambda x: '{}.{:0>2}'.format(x[1], x[2])), errors='coerce')\n",
    "df['CREDIT.HISTORY.LENGTH'] = df['CREDIT.HISTORY.LENGTH'].apply(lambda x: (math.modf(x)[0]*6)+math.modf(x)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method 6\n",
    "def calculate_months_from_strings(text):\n",
    "    number_list = [int(s) for s in re.findall(r'\\d+', text)]\n",
    "    result = []\n",
    "    for i in range(0,len(number_list)):\n",
    "        if (i == 0):\n",
    "            result.append(number_list[i] * 12)\n",
    "        else:\n",
    "            result.append(number_list[i])\n",
    "    output = sum(result)\n",
    "    return output\n",
    "\n",
    "train['AVERAGE.ACCT.AGE'] = train['AVERAGE.ACCT.AGE'].apply(calculate_months_from_strings)\n",
    "train['CREDIT.HISTORY.LENGTH'] = train['CREDIT.HISTORY.LENGTH'].apply(calculate_months_from_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform CNS Score Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method 1\n",
    "train['PERFORM_CNS.SCORE.BINS']=pd.cut(train['PERFORM_CNS.SCORE'],5,labels=['Slim','Doubtful','Fair','Good','Great']).astype(np.object)\n",
    "train['PERFORM_CNS.SCORE.DESCRIPTION'].replace({'C-Very Low Risk':'Very Low Risk','A-Very Low Risk':'Very Low Risk','D-Very Low Risk':'Very Low Risk','B-Very Low Risk':'Very Low Risk',\n",
    "'M-Very High Risk':'Very High Risk','L-Very High Risk':'Very High Risk',\n",
    "                                               'F-Low Risk':'Low Risk','E-Low Risk':'Low Risk',\n",
    "                                               'H-Medium Risk':'Medium Risk','I-Medium Risk':'Medium Risk',\n",
    "                                               'J-High Risk':'High Risk','K-High Risk':'High Risk'},inplace=True)\n",
    "train['Not_Scored']=np.where(train['PERFORM_CNS.SCORE.DESCRIPTION'].str.contains('Not Scored'),1,0)\n",
    "train['Very_Low']=np.where(train['PERFORM_CNS.SCORE.DESCRIPTION'].str.contains('Very Low'),1,0)\n",
    "train['Very_High']=np.where(train['PERFORM_CNS.SCORE.DESCRIPTION'].str.contains('Very High'),1,0)\n",
    "train['No_History']=np.where(train['PERFORM_CNS.SCORE.DESCRIPTION'].str.contains('No Bureau'),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method 2\n",
    "def CIBIL_norm(x):\n",
    "    a=''\n",
    "    if((x=='A-Very Low Risk') or (x=='B-Very Low Risk') or (x=='C-Very Low Risk') or (x=='D-Very Low Risk')):\n",
    "        a = 'Very Low Risk'\n",
    "    elif((x=='M-Very High Risk')):\n",
    "        a = 'Very Very High Risk'\n",
    "    elif((x=='L-Very High Risk')):\n",
    "        a='Very High Risk'\n",
    "    elif((x=='E-Low Risk') or (x=='F-Low Risk') or (x=='G-Low Risk')):\n",
    "        a = 'Low Risk'\n",
    "    elif((x=='H-Medium Risk') or (x=='I-Medium Risk')):\n",
    "        a = 'Medium Risk'\n",
    "    elif((x=='J-High Risk') or (x=='K-High Risk')):\n",
    "        a = 'High Risk'\n",
    "    elif((x=='Not Scored: No Activity seen on the customer (Inactive)') or (x=='Not Scored: No Updates available in last 36 months')):\n",
    "        a = 'Inactive'\n",
    "    elif((x=='Not Scored: Only a Guarantor')):\n",
    "        a='Guarantor'\n",
    "    elif((x=='Not Scored: More than 50 active Accounts found')):\n",
    "        a='SuperActive'\n",
    "    else:\n",
    "        a='Others'\n",
    "    return a\n",
    "\n",
    "def CIBIL_other(x):\n",
    "    a=''\n",
    "    if((x=='A-Very Low Risk') or (x=='B-Very Low Risk') or (x=='C-Very Low Risk') or (x=='D-Very Low Risk')):\n",
    "        a = 'Very Low Risk'\n",
    "    elif((x=='M-Very High Risk')):\n",
    "        a = 'Very Very High Risk'\n",
    "    elif((x=='L-Very High Risk')):\n",
    "        a='Very High Risk'\n",
    "    elif((x=='E-Low Risk') or (x=='F-Low Risk') or (x=='G-Low Risk')):\n",
    "        a = 'Low Risk'\n",
    "    elif((x=='H-Medium Risk') or (x=='I-Medium Risk')):\n",
    "        a = 'Medium Risk'\n",
    "    elif((x=='J-High Risk') or (x=='K-High Risk')):\n",
    "        a = 'High Risk'\n",
    "    elif((x=='Not Scored: No Activity seen on the customer (Inactive)') or (x=='Not Scored: No Updates available in last 36 months')):\n",
    "        a = 'Inactive'\n",
    "    elif((x=='Not Scored: Only a Guarantor')):\n",
    "        a='Guarantor'\n",
    "    elif((x=='Not Scored: More than 50 active Accounts found')):\n",
    "        a='SuperActive'\n",
    "    elif((x=='No Bureau History Available') or (x=='Not Scored: Sufficient History Not Available') or (x=='Not Scored: Not Enough Info available on the customer')):  \n",
    "        a='NoHistory'\n",
    "    else:\n",
    "        a='Others'\n",
    "    return a\n",
    "\n",
    "train['CIBIL_Descr'] = train['PERFORM_CNS.SCORE.DESCRIPTION'].apply(CIBIL_norm)\n",
    "train['CIBIL_Other'] = train['PERFORM_CNS.SCORE.DESCRIPTION'].apply(CIBIL_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method 3\n",
    "train['PERFORM_CNS.SCORE.DESCRIPTION'] = train['PERFORM_CNS.SCORE.DESCRIPTION'].map({'No Bureau History Available':6,  \n",
    "    'I-Medium Risk':9,  'L-Very High Risk':12, \n",
    "'A-Very Low Risk':1, \n",
    "    'Not Scored: Not Enough Info available on the customer':6, \n",
    "'D-Very Low Risk':4,  'M-Very High Risk':13,  'B-Very Low Risk':2,  'C-Very Low Risk':3, \n",
    "'E-Low Risk':5,  'H-Medium Risk':8,  'F-Low Risk':6,  'K-High Risk':11, \n",
    "'Not Scored: No Activity seen on the customer (Inactive)':6, \n",
    "'Not Scored: Sufficient History Not Available':6, \n",
    "'Not Scored: No Updates available in last 36 months':6,  'G-Low Risk':7, \n",
    "'J-High Risk':10,  'Not Scored: Only a Guarantor':6, \n",
    "'Not Scored: More than 50 active Accounts found':10 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method 4 \n",
    "train['PERFORM_CNS.SCORE.DESCRIPTION'] = train['PERFORM_CNS.SCORE.DESCRIPTION'].apply(lambda x: 'No Info' if (x=='No Bureau History Available') else x )\n",
    "train['PERFORM_CNS.SCORE.DESCRIPTION'] = train['PERFORM_CNS.SCORE.DESCRIPTION'].apply(lambda x: 'No Info' if (x=='Not Scored: Sufficient History Not Available') else x )\n",
    "train['PERFORM_CNS.SCORE.DESCRIPTION'] = train['PERFORM_CNS.SCORE.DESCRIPTION'].apply(lambda x: 'No Info' if (x=='Not Scored: Not Enough Info available on the customer') else x )\n",
    "train['PERFORM_CNS.SCORE.DESCRIPTION'] = train['PERFORM_CNS.SCORE.DESCRIPTION'].apply(lambda x: 'No Info' if (x=='Not Scored: No Activity seen on the customer (Inactive)') else x )\n",
    "train['PERFORM_CNS.SCORE.DESCRIPTION'] = train['PERFORM_CNS.SCORE.DESCRIPTION'].apply(lambda x: 'No Info' if (x=='Not Scored: No Updates available in last 36 months') else x )\n",
    "train['PERFORM_CNS.SCORE.DESCRIPTION'] = train['PERFORM_CNS.SCORE.DESCRIPTION'].apply(lambda x: 'No Info' if (x=='Not Scored: Only a Guarantor') else x )\n",
    "train['PERFORM_CNS.SCORE.DESCRIPTION'] = train['PERFORM_CNS.SCORE.DESCRIPTION'].apply(lambda x: 'No Info' if (x=='Not Scored: More than 50 active Accounts found') else x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method 5\n",
    "PERFORM_CNS_SCORE_DESCRIPTION__LE__Dict  =  {'A-Very Low Risk':0.05, \n",
    "                                             'B-Very Low Risk':0.1, \n",
    "                                             'C-Very Low Risk':0.3, \n",
    "                                             'D-Very Low Risk':0.8, \n",
    "                                             \n",
    "                                             'E-Low Risk':1.1, \n",
    "                                             'F-Low Risk':1.4, \n",
    "                                             'G-Low Risk':1.8, \n",
    "                                             \n",
    "                                             'H-Medium Risk':2.7,\n",
    "                                             'I-Medium Risk':3.9,\n",
    "                                             \n",
    "                                             'J-High Risk':5,\n",
    "                                             'K-High Risk':6,\n",
    "                                             \n",
    "                                             'L-Very High Risk':7.5,\n",
    "                                             'M-Very High Risk':10}    # Weights.\n",
    "\n",
    "count_of_AtoM  =  sum([count__PERFORM_CNS_SCORE_DESCRIPTION__Dict[i]     for i in PERFORM_CNS_SCORE_DESCRIPTION__LE__Dict])\n",
    "count__PERFORM_CNS_SCORE_DESCRIPTION__Dict____minus____PERFORM_CNS_SCORE_DESCRIPTION__LE__Dict  =  [i  for i in count__PERFORM_CNS_SCORE_DESCRIPTION__Dict  if i not in PERFORM_CNS_SCORE_DESCRIPTION__LE__Dict]\n",
    "\n",
    "# Weighted Average\n",
    "weighted_avg =  sum([PERFORM_CNS_SCORE_DESCRIPTION__LE__Dict[i] * (count__PERFORM_CNS_SCORE_DESCRIPTION__Dict[i]/count_of_AtoM)  for i in PERFORM_CNS_SCORE_DESCRIPTION__LE__Dict])\n",
    "for i in count__PERFORM_CNS_SCORE_DESCRIPTION__Dict____minus____PERFORM_CNS_SCORE_DESCRIPTION__LE__Dict:\n",
    "        PERFORM_CNS_SCORE_DESCRIPTION__LE__Dict[i]  =  weighted_avg\n",
    "\n",
    "df['PERFORM_CNS.SCORE.DESCRIPTION__Weighted_Average'] = [PERFORM_CNS_SCORE_DESCRIPTION__LE__Dict[i]  for i in df['PERFORM_CNS.SCORE.DESCRIPTION']]\n",
    "\n",
    "# Average\n",
    "_avg   =  sum([PERFORM_CNS_SCORE_DESCRIPTION__LE__Dict[i]   for i in PERFORM_CNS_SCORE_DESCRIPTION__LE__Dict]) / len(PERFORM_CNS_SCORE_DESCRIPTION__LE__Dict)\n",
    "for i in count__PERFORM_CNS_SCORE_DESCRIPTION__Dict____minus____PERFORM_CNS_SCORE_DESCRIPTION__LE__Dict:\n",
    "        PERFORM_CNS_SCORE_DESCRIPTION__LE__Dict[i]  =  _avg\n",
    "\n",
    "df['PERFORM_CNS.SCORE.DESCRIPTION__Average'] = [PERFORM_CNS_SCORE_DESCRIPTION__LE__Dict[i]  for i in df['PERFORM_CNS.SCORE.DESCRIPTION']]\n",
    "\n",
    "\n",
    "# Categorical\n",
    "PERFORM_CNS_SCORE_DESCRIPTION__LE__Dict  =  dict((value, key) for (key, value) in enumerate(sorted(df['PERFORM_CNS.SCORE.DESCRIPTION'].unique())))\n",
    "df['PERFORM_CNS.SCORE.DESCRIPTION__Categorical'] = [PERFORM_CNS_SCORE_DESCRIPTION__LE__Dict[i]  for i in df['PERFORM_CNS.SCORE.DESCRIPTION']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform CNS Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CIBIL_trend(x):\n",
    "    a=''\n",
    "    if(x==300):\n",
    "        a='Very Poor'\n",
    "    elif((x>300) and (x<=550)):\n",
    "        a='Poor'\n",
    "    elif((x>550) and (x<=650)):\n",
    "        a='Fair'\n",
    "    elif((x>650) and (x<=750)):\n",
    "        a='Good'\n",
    "    elif((x>750) and (x<=900)):\n",
    "        a='Excellent'\n",
    "    else:\n",
    "        a='Others'\n",
    "    return a\n",
    "train['CIBIL_Trend'] = train['PERFORM_CNS.SCORE'].apply(CIBIL_trend)\n",
    "train['PERFORM_CNS.SCORE'] = np.where(train['PERFORM_CNS.SCORE']==11,0,train['PERFORM_CNS.SCORE'])\n",
    "train['PERFORM_CNS.SCORE'] = np.where(train['PERFORM_CNS.SCORE']==14,0,train['PERFORM_CNS.SCORE'])\n",
    "train['PERFORM_CNS.SCORE'] = np.where(train['PERFORM_CNS.SCORE']==15,0,train['PERFORM_CNS.SCORE'])\n",
    "train['PERFORM_CNS.SCORE'] = np.where(train['PERFORM_CNS.SCORE']==16,0,train['PERFORM_CNS.SCORE'])\n",
    "train['PERFORM_CNS.SCORE'] = np.where(train['PERFORM_CNS.SCORE']==17,0,train['PERFORM_CNS.SCORE'])\n",
    "train['PERFORM_CNS.SCORE'] = np.where(train['PERFORM_CNS.SCORE']==18,0,train['PERFORM_CNS.SCORE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features based on Primary and Secondary Accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"PRI.Total.loan\"] = train[\"PRI.CURRENT.BALANCE\"] + train[\"PRI.SANCTIONED.AMOUNT\"]\n",
    "train['total_accounts'] = train['PRI.NO.OF.ACCTS'] + train['SEC.NO.OF.ACCTS']\n",
    "train['total_install_amt'] = train['PRIMARY.INSTAL.AMT'] + train['SEC.INSTAL.AMT']\n",
    "train['Total.ACTIVE.ACCTS'] = train['PRI.ACTIVE.ACCTS'] + train['SEC.ACTIVE.ACCTS']\n",
    "train['TOT.CURRENT.BALANCE'] = train['PRI.CURRENT.BALANCE'] + train['SEC.CURRENT.BALANCE']\n",
    "train['TOT.DISBURSED.AMOUNT'] = train['PRI.DISBURSED.AMOUNT'] + train['SEC.DISBURSED.AMOUNT']\n",
    "train['Total.OVERDUE.ACCTS'] = train['PRI.OVERDUE.ACCTS'] + train['SEC.OVERDUE.ACCTS']\n",
    "train['Total.SANCTIONED.AMOUNT'] = train['PRI.SANCTIONED.AMOUNT'] + train['SEC.SANCTIONED.AMOUNT']\n",
    "train['PriOverduePercentage'] = np.where(train['PRI.NO.OF.ACCTS'] != 0,train['PRI.OVERDUE.ACCTS'] / train['PRI.NO.OF.ACCTS'],-1)\n",
    "\n",
    "train['instalment_flag'] = np.where(np.logical_and(train['PRIMARY.INSTAL.AMT'] > 0, train['SEC.INSTAL.AMT'] > 0),1,0)\n",
    "train['outstanding_now'] = train['PRI.CURRENT.BALANCE'] + train['disbursed_amount']\n",
    "train['disbursed_amount_by_PRI_EMI'] = train['disbursed_amount'] / train['PRIMARY.INSTAL.AMT']\n",
    "train['PRI.NO.OF.ACCTS.Deacti'] = train['PRI.NO.OF.ACCTS'] - train['PRI.ACTIVE.ACCTS']\n",
    "train['loan_paid_PRI'] = train['PRI.DISBURSED.AMOUNT'] - train['PRI.CURRENT.BALANCE']\n",
    "train[\"total_sanctioned\"] = (train[\"SEC.SANCTIONED.AMOUNT\"] + train[\"SEC.SANCTIONED.AMOUNT\"]).clip(0, 1e9)\n",
    "train['SecOverduePercentage'] = np.where(train['SEC.NO.OF.ACCTS'] != 0,train['SEC.OVERDUE.ACCTS'] / train['SEC.NO.OF.ACCTS'],-1)\n",
    "train['SECcritRatio'] = np.where(train['SEC.DISBURSED.AMOUNT'] != 0,train['SEC.CURRENT.BALANCE'] / train['SEC.DISBURSED.AMOUNT'],-1)\n",
    "train['TOTcritRatio'] = np.where(train['TOT.DISBURSED.AMOUNT'] != 0,train['TOT.CURRENT.BALANCE'] / train['TOT.DISBURSED.AMOUNT'],-1)\n",
    "train['disbursed_amount_by_SEC_EMI'] = train['disbursed_amount'] / train['SEC.INSTAL.AMT']\n",
    "train['SEC.NO.OF.ACCTS.Deacti'] = train['SEC.NO.OF.ACCTS'] - train['SEC.ACTIVE.ACCTS']\n",
    "train['loan_paid_Sec'] = train['SEC.DISBURSED.AMOUNT'] - train['SEC.CURRENT.BALANCE']\n",
    "train['SANCTION_DISBURSED']=train['Total.SANCTIONED.AMOUNT'] - train['TOT.DISBURSED.AMOUNT']\n",
    "train['NO_DEACTIVE_ACCOUNTS'] = train['total_accounts'] - train['Total.ACTIVE.ACCTS']\n",
    "train['NO.OF.ACC.BEF.SIX.MONTH'] = train['total_accounts'] - train['NEW.ACCTS.IN.LAST.SIX.MONTHS']\n",
    "train['CLEAN.ACC'] = train['total_accounts'] - (train['Total.ACTIVE.ACCTS'] + train['Total.OVERDUE.ACCTS'])\n",
    "train['asset_value'] = train['disbursed_amount'] * (train['ltv']/100)\n",
    "train['value_cost'] = train['asset_cost'] - train['asset_value']\n",
    "train['value_per_cost'] = train['value_cost'] / train['asset_value']\n",
    "train['extra_finance'] = train['asset_cost'] * (train['ltv']/100) - train['disbursed_amount']\n",
    "train['asset_disburse'] = (train['asset_cost'] - train['disbursed_amount']) / train['disbursed_amount']\n",
    "train['sixmmonths_trainault'] = train['NEW.ACCTS.IN.LAST.SIX.MONTHS'] - train['DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS']\n",
    "train['disbursed_tot'] = train['disbursed_amount'] + train['PRI.DISBURSED.AMOUNT']\n",
    "train['out_to_dsbrsd'] = train['outstanding_now'] / train['disbursed_tot']\n",
    "train['dis_as_share'] = train['asset_cost'] / train['disbursed_amount']\n",
    "train['diff_ltv_'] = train['dis_as_share'] - train['ltv']\n",
    "train['isStudent'] = np.where(train['Age']<=25,1,0)\n",
    "train['isSenior'] = np.where(train['Age']>=60,1,0)\n",
    "train['ass_by_ltv'] = train['asset_cost'] / train['ltv']\n",
    "# df['AVERAGE.ACCT.AGE'] = pd.to_numeric(df['AVERAGE.ACCT.AGE'].str.replace(r'(\\d+).*(\\d+).*', lambda x: '{}.{:0>2}'.format(x[1], x[2])), errors='coerce')\n",
    "# df['AVERAGE.ACCT.AGE'] = df['AVERAGE.ACCT.AGE'].apply(lambda x: (math.modf(x)[0]*6)+math.modf(x)[1])\n",
    "train['avg_instalment'] = np.where(train['AVERAGE.ACCT.AGE'] > 0,train['TOT.DISBURSED.AMOUNT']/train['AVERAGE.ACCT.AGE'],train['AVERAGE.ACCT.AGE'])\n",
    "train['more_instalment_flag'] = np.where(train['total_install_amt'] > train['avg_instalment'], 1, 0)\n",
    "train['same_sanctioned_flag'] = np.where(train['Total.SANCTIONED.AMOUNT'] == train['TOT.DISBURSED.AMOUNT'],True,False)\n",
    "train['avg_disbursed_amt'] = np.where(train['total_accounts'] > 0,train['TOT.DISBURSED.AMOUNT']/train['total_accounts'],train['total_accounts'])\n",
    "train['more_disbursed_flag'] = np.where(train['disbursed_amount'] > train['avg_disbursed_amt'], 1, 0)\n",
    "train['disbursed_amt_diff'] = train['disbursed_amount'] - train['avg_disbursed_amt']\n",
    "# df['CREDIT.HISTORY.LENGTH'] = pd.to_numeric(df['CREDIT.HISTORY.LENGTH'].str.replace(r'(\\d+).*(\\d+).*', lambda x: '{}.{:0>2}'.format(x[1], x[2])), errors='coerce')\n",
    "# df['CREDIT.HISTORY.LENGTH'] = df['CREDIT.HISTORY.LENGTH'].apply(lambda x: (math.modf(x)[0]*6)+math.modf(x)[1])\n",
    "train['young_risk_cust'] = np.where(np.logical_and(train['Age'] < 25,train['CREDIT.HISTORY.LENGTH'] == 0),True,False)\n",
    "train['overdue_ratio'] = np.where(train['total_accounts'] > 0,train['Total.OVERDUE.ACCTS']/train['total_accounts'],train['total_accounts'])\n",
    "train['active_ratio'] = np.where(np.logical_and(train['Total.ACTIVE.ACCTS'] > 0, train['Total.ACTIVE.ACCTS'] > 0),(train['Total.ACTIVE.ACCTS'] - train['Total.OVERDUE.ACCTS'])/train['total_accounts'],0)\n",
    "train['active_ratio'] = np.clip(train['active_ratio'], a_min=0, a_max = 1)\n",
    "train['success_ratio'] = np.where(train['total_accounts'] == train['Total.ACTIVE.ACCTS'],0,np.where(train['total_accounts'] > 0\n",
    "                                              ,(train['total_accounts'] - train['Total.ACTIVE.ACCTS'])/train['total_accounts'],train['total_accounts']))\n",
    "train['instalment_flag'] = np.where(np.logical_and(train['PRIMARY.INSTAL.AMT'] > 0\n",
    "                                                    , train['SEC.INSTAL.AMT'] > 0),1,0)\n",
    "train['paid_percent'] = np.where(train['TOT.DISBURSED.AMOUNT'] > 0,(train['TOT.DISBURSED.AMOUNT'] - train['TOT.CURRENT.BALANCE'])/ \n",
    "                                 train['TOT.DISBURSED.AMOUNT'],train['TOT.DISBURSED.AMOUNT'])\n",
    "train['instalment_ratio'] = np.where(train['TOT.CURRENT.BALANCE'] > 0,train['total_install_amt']/train['TOT.CURRENT.BALANCE']\n",
    "                                              ,train['TOT.CURRENT.BALANCE'])\n",
    "train['recent_bad_accnt_flag'] = np.where(train['DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS'] > 0, 1, 0)\n",
    "train['recent_open_accnt_flag'] = np.where(train['NEW.ACCTS.IN.LAST.SIX.MONTHS'] > 0, 1, 0)\n",
    "train['inquire_flag'] = np.where(train['NO.OF_INQUIRIES'] > 0, 1, 0)\n",
    "train['id_score'] = (train['Aadhar_flag'] + train['PAN_flag'] + train['VoterID_flag'] + \n",
    "                        train['Driving_flag'] + train['Passport_flag'])\n",
    "train['dtv'] = round(100*train['disbursed_amount']/train['asset_cost'],2)\n",
    "train['diff_ltv_dtv'] = train['ltv'] - train['dtv']\n",
    "train['high_loan_flag'] = np.where(train['loan_amt'] > train['disbursed_amount'], 1, 0)\n",
    "train['totalDefaultPercent'] = np.where((train['PRI.NO.OF.ACCTS'] + train['SEC.NO.OF.ACCTS']) != 0,(train['PRI.OVERDUE.ACCTS'] + train['SEC.OVERDUE.ACCTS'])/(train['PRI.NO.OF.ACCTS'] + train['SEC.NO.OF.ACCTS']),-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some unique features from each Kernel "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anomalous Branch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "branchList = train['branch_id'].unique()\n",
    "branchSupId = train.groupby('branch_id')['supplier_id'].unique()\n",
    "branchSupIdList = []\n",
    "anomalousBranch = []\n",
    "for bra in range(len(branchList)):\n",
    "    branchId = branchList[bra]\n",
    "    branchSupIdList.append(branchSupId[branchId])\n",
    "\n",
    "for i in range(len(branchSupIdList)):\n",
    "    for j in range(len(branchSupIdList)):\n",
    "        if(i != j):\n",
    "                #print(len(list(set(branchSupIdList[i]).intersection(set(branchSupIdList[j])))))\n",
    "                if ((len(list(set(branchSupIdList[i]).intersection(set(branchSupIdList[j]))))) != 0):  \n",
    "                    if (len(list(set(branchSupIdList[i]).intersection(set(branchSupIdList[j]))))) >= 3:  \n",
    "                          #Both branches in the same locality.\n",
    "                            continue\n",
    "                    else:\n",
    "                        anomalousBranch.append(branchList[i])\n",
    "                else:#Disjoint Branches\n",
    "                    continue\n",
    "        else:\n",
    "            continue \n",
    "\n",
    "def isBranchAnomalous(x):\n",
    "    if (x in anomalousBranch):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "train['isBranchAnomalous'] = train['branch_id'].apply(lambda x: isBranchAnomalous(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Current_Outstanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a new feature based on the Number of outstanding Balance accounts the customer has.\n",
    "# The idea behind this being, more the number of accounts a customer has with outstanding balance, the less reliable he would be expected to be.\n",
    "def CurrOutstandingBal(x):\n",
    "    a=''\n",
    "    if (x==0):\n",
    "        a='Good'\n",
    "    elif((x<0) and (x!=-1)):\n",
    "        a='Very Good'\n",
    "    elif(x>0 and x<=1):\n",
    "        a='Both'\n",
    "    elif(x>1):\n",
    "        a='Problematic'\n",
    "    else:\n",
    "        a='Other'\n",
    "    return a\n",
    "\n",
    "# train['PRIcritRatio'] = np.where(train['PRI.DISBURSED.AMOUNT'] != 0,train['PRI.CURRENT.BALANCE'] / train['PRI.DISBURSED.AMOUNT'],-1)\n",
    "train['PriRatioRemark'] = train['PRIcritRatio'].apply(lambda x: CurrOutstandingBal(x))\n",
    "\n",
    "# train['SECcritRatio'] = np.where(train['SEC.DISBURSED.AMOUNT'] != 0,train['SEC.CURRENT.BALANCE'] / train['SEC.DISBURSED.AMOUNT'],-1)\n",
    "train['SecRatioRemark'] = train['SECcritRatio'].apply(lambda x: CurrOutstandingBal(x))\n",
    "\n",
    "# train['TOTcritRatio'] = np.where(train['TOT.DISBURSED.AMOUNT'] != 0,train['TOT.CURRENT.BALANCE'] / train['TOT.DISBURSED.AMOUNT'],-1)\n",
    "train['TotRatioRemark'] = train['TOTcritRatio'].apply(lambda x: CurrOutstandingBal(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prime Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrimaDefault(x):\n",
    "    a=''\n",
    "    if(x==-1):\n",
    "        a='First'\n",
    "    elif(x==0):\n",
    "        a='Great'\n",
    "    elif(x<=0.2):\n",
    "        a='Normal'\n",
    "    elif(x<=0.4):\n",
    "        a='Bothersome'\n",
    "    elif(x<=0.6):\n",
    "        a='Trouble'\n",
    "    elif(x<=0.8):\n",
    "        a='Danger'\n",
    "    else:\n",
    "        a='High Alert'\n",
    "    return a\n",
    "# PriOverduePercentage'] = np.where(train['PRI.NO.OF.ACCTS'] != 0,train['PRI.OVERDUE.ACCTS'] / train['PRI.NO.OF.ACCTS'],-1)\n",
    "train['PrimaDefaultRemark'] = train['PriOverduePercentage'].apply(lambda x: PrimaDefault(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Secondary Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SecDefault(x):\n",
    "    a=''\n",
    "    if(x==-1):\n",
    "        a='First'\n",
    "    elif(x==0):\n",
    "        a='Great'\n",
    "    elif(x<=0.2):\n",
    "        a='Normal'\n",
    "    elif(x<=0.4):\n",
    "        a='Bothersome'\n",
    "    elif(x<=0.6):\n",
    "        a='Trouble'\n",
    "    elif(x<=0.8):\n",
    "        a='Danger'\n",
    "    else:\n",
    "        a='High Alert'\n",
    "    return a\n",
    "\n",
    "# train['SecOverduePercentage'] = np.where(train['SEC.NO.OF.ACCTS'] != 0,train['SEC.OVERDUE.ACCTS'] / train['SEC.NO.OF.ACCTS'],-1)\n",
    "train['SecoDefaultRemark'] = train['SecOverduePercentage'].apply(lambda x: SecDefault(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TotDefault(x):\n",
    "    a=''\n",
    "    if(x==-1):\n",
    "        a='First'\n",
    "    elif(x==0):\n",
    "        a='Great'\n",
    "    elif(x<=0.2):\n",
    "        a='Normal'\n",
    "    elif(x<=0.4):\n",
    "        a='Bothersome'\n",
    "    elif(x<=0.6):\n",
    "        a='Trouble'\n",
    "    elif(x<=0.8):\n",
    "        a='Danger'\n",
    "    else:\n",
    "        a='High Alert'\n",
    "    return a\n",
    "\n",
    "# train['totalDefaultPercent'] = np.where((train['PRI.NO.OF.ACCTS'] + train['SEC.NO.OF.ACCTS']) != 0,(train['PRI.OVERDUE.ACCTS'] + train['SEC.OVERDUE.ACCTS'])/(train['PRI.NO.OF.ACCTS'] + train['SEC.NO.OF.ACCTS']),-1)\n",
    "train['TotaDefaultRemark'] = train['totalDefaultPercent'].apply(lambda x: TotDefault(x)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Default in Last Six Months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrimaDefaultLastSix(x):\n",
    "    a=''\n",
    "    if(x==0):\n",
    "        a='Great'\n",
    "    elif(x==1):\n",
    "        a='Normal'\n",
    "    elif(x==2):\n",
    "        a='Bothersome'\n",
    "    elif(x>=3):\n",
    "        a='Trouble'\n",
    "    else:\n",
    "        a='Others'\n",
    "    return a\n",
    "\n",
    "train['AcctsLastSixRemarks'] = train['DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS'].apply(lambda x : PrimaDefaultLastSix(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features based on Groupby Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1, col2 in [[\"asset_cost\", \"disbursed_amount\"],\n",
    "                   [\"PRI.DISBURSED.AMOUNT\", \"PRI.CURRENT.BALANCE\"],\n",
    "                  ]:\n",
    "    train[col1 + \"_diff_\" + col2] = train[col1] - train[col2]\n",
    "\n",
    "\n",
    "for col1, col2 in [[\"PRI.CURRENT.BALANCE\", \"PRI.DISBURSED.AMOUNT\"],\n",
    "                   [\"PRI.DISBURSED.AMOUNT\", \"PRI.SANCTIONED.AMOUNT\"],\n",
    "                   [\"AVERAGE.ACCT.AGE\", \"CREDIT.HISTORY.LENGTH\"],\n",
    "                   [\"PRI.ACTIVE.ACCTS\", \"PRI.NO.OF.ACCTS\"],\n",
    "                   [\"PRI.OVERDUE.ACCTS\", \"PRI.ACTIVE.ACCTS\"],\n",
    "                   [\"PRI.OVERDUE.ACCTS\", \"PRI.NO.OF.ACCTS\"]]:\n",
    "    train[col1+\"_ratio_\"+col2] = train[col1] / train[col2]\n",
    "\n",
    "\n",
    "for col in [\"Current_pincode_ID\", \"Employee_code_ID\", \"supplier_id\", \"branch_id\", \"ltv\", \n",
    "            [\"supplier_id\", \"branch_id\"], [\"supplier_id\", \"Employee_code_ID\"],\n",
    "            [\"manufacturer_id\", \"branch_id\"], [\"manufacturer_id\", \"Employee_code_ID\"],\n",
    "            [\"Employment.Type\", \"Employee_code_ID\"], [\"Employment.Type\", \"branch_id\"],\n",
    "            [\"PERFORM_CNS.SCORE.DESCRIPTION\", \"Employee_code_ID\"],\n",
    "            [\"Current_pincode_ID\", \"Employee_code_ID\"]]:\n",
    "    if not isinstance(col, list):\n",
    "        col = [col]\n",
    "    col_name = \"_\".join(col)\n",
    "    all_df = pd.concat([train[[\"UniqueID\"]+ col], test[[\"UniqueID\"]+ col]])\n",
    "    gdf = all_df.groupby(col)[\"UniqueID\"].count().reset_index()\n",
    "    gdf.columns = col + [col_name+\"_count\"]\n",
    "    train = pd.merge(train, gdf, on=col, how=\"left\")\n",
    "       \n",
    "for col in [\"Current_pincode_ID\", \"Employee_code_ID\", \"supplier_id\"]:\n",
    "    if not isinstance(col, list):\n",
    "        col = [col]\n",
    "    col_name = \"_\".join(col)\n",
    "    all_df = pd.concat([train[[\"ltv\"]+ col], test[[\"ltv\"]+ col]])\n",
    "    gdf = all_df.groupby(col)[\"ltv\"].agg([\"mean\", \"std\", \"max\"]).reset_index()\n",
    "    gdf.columns = col + [col_name+\"_ltv_mean\", col_name+\"_ltv_std\", col_name+\"_ltv_max\"]\n",
    "    train = pd.merge(train, gdf, on=col, how=\"left\")\n",
    "\n",
    "\n",
    "for col in [\"Current_pincode_ID\", \"Employee_code_ID\"]:\n",
    "    if not isinstance(col, list):\n",
    "        col = [col]\n",
    "    col_name = \"_\".join(col)\n",
    "    all_df = pd.concat([train[[\"PERFORM_CNS.SCORE\"]+ col], test[[\"PERFORM_CNS.SCORE\"]+ col]])\n",
    "    gdf = all_df.groupby(col)[\"PERFORM_CNS.SCORE\"].agg([\"mean\", \"std\"]).reset_index()\n",
    "    gdf.columns = col + [col_name+\"_performance_mean\", col_name+\"_performance_std\"]\n",
    "    train = pd.merge(train, gdf, on=col, how=\"left\")\n",
    "    \n",
    "    all_df = pd.concat([train[[\"Date.of.Birth_in_seconds\"]+ col], test[[\"Date.of.Birth_in_seconds\"]+ col]])\n",
    "    gdf = all_df.groupby(col)[\"Date.of.Birth_in_seconds\"].agg([\"mean\", \"std\"]).reset_index()\n",
    "    gdf.columns = col + [col_name+\"_dob_mean\", col_name+\"_dob_std\"]\n",
    "    train = pd.merge(train, gdf, on=col, how=\"left\")\n",
    "    \n",
    "    all_df = pd.concat([train[[\"disbursed_amount\"]+ col], test[[\"disbursed_amount\"]+ col]])\n",
    "    gdf = all_df.groupby(col)[\"disbursed_amount\"].agg([\"mean\", \"std\"]).reset_index()\n",
    "    gdf.columns = col + [col_name+\"_disamount_mean\", col_name+\"_disamount_std\"]\n",
    "    train = pd.merge(train, gdf, on=col, how=\"left\")\n",
    "    \n",
    "    all_df = pd.concat([train[[\"DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS\"]+ col], test[[\"DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS\"]+ col]])\n",
    "    gdf = all_df.groupby(col)[\"DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS\"].mean().reset_index()\n",
    "    gdf.columns = col + [col_name+\"_delinq_mean\"]\n",
    "    train = pd.merge(train, gdf, on=col, how=\"left\")\n",
    "    \n",
    "    all_df = pd.concat([train[[\"PRI.OVERDUE.ACCTS\"]+ col], test[[\"PRI.OVERDUE.ACCTS\"]+ col]])\n",
    "    gdf = all_df.groupby(col)[\"PRI.OVERDUE.ACCTS\"].mean().reset_index()\n",
    "    gdf.columns = col + [col_name+\"_overdue_mean\"]\n",
    "    train = pd.merge(train, gdf, on=col, how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Outlier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a5532e66d8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(train['disbursed_amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train[train['disbursed_amount']<200000].reset_index(drop=True)\n",
    "train.drop(index = [48879,85588,134575], axis=0, inplace= True)\n",
    "train.reset_index(inplace= True)\n",
    "train.drop('index', axis= 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing in Employment Type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7661"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Employment.Type'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Employment.Type'].fillna(1, inplace=True)\n",
    "df['Employment.Type'] = df['Employment.Type'].map({'Salaried':2, 'Self employed':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Employment.Type'] = np.where(train['Employment.Type'].isnull(),'Unemployed',train['Employment.Type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard Scaler \n",
    "scaler=StandardScaler()\n",
    "col=train.columns.difference(['loan_default']).values\n",
    "train=pd.concat([pd.DataFrame(scaler.fit_transform(train.drop('loan_default',axis=1)),columns=col),train['loan_default'].reset_index(drop=True)],axis=1)\n",
    "test=pd.DataFrame(scaler.fit_transform(test),columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Quantile Scaler/Transformer\n",
    "def scale_data(train, test, feats):\n",
    "    scaler = QuantileTransformer(output_distribution=\"normal\", n_quantiles=2000, subsample=5e5, random_state=12345786)\n",
    "    df_all = pd.concat([train[feats], test[feats]], axis=0)\n",
    "    scaler.fit(df_all)\n",
    "    qnt_feats = [f+\"_qnt\" for f in feats]\n",
    "    train_qnt = pd.DataFrame(scaler.transform(train[feats]), columns=qnt_feats)\n",
    "    test_qnt = pd.DataFrame(scaler.transform(test[feats]), columns=qnt_feats)\n",
    "    return train_qnt, test_qnt\n",
    "# feats --> this will contains the lis of features for features transform \n",
    "feats = []\n",
    "train, test = scale_data(train, test, feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "ros = RandomUnderSampler(random_state=0)\n",
    "ros.fit(X, y)\n",
    "X_resampled, y_resampled = ros.fit_sample(X, y)\n",
    "colors = ['#ef8a62' if v == 0 else '#f7f7f7' if v == 1 else '#67a9cf' for v in y_resampled]\n",
    "plt.scatter(X_resampled[:, 0], X_resampled[:, 1], c=colors, linewidth=0.5, edgecolor='black')\n",
    "sns.despine()\n",
    "plt.title(\"RandomUnderSampler Output ($n_{class}=4700)$\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a training set for modeling and validation set to check model performance\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, train_size=0.7, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratified Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=['loan_default'])\n",
    "y = train['loan_default']\n",
    "data = pd.concat([X, test], axis = 0)\n",
    "data['is_test'] = np.zeros(345546)\n",
    "data.iloc[233154:,-1] = 1\n",
    "train_examples = train.shape[0]\n",
    "data_x = data.drop('is_test', axis=1)\n",
    "data_y = data['is_test']\n",
    "is_test_probs = cross_val_predict(RandomForestClassifier(max_depth = 7,n_estimators=200), data_x, data_y, method='predict_proba')[:train_examples]\n",
    "is_test_Probs = is_test_probs[:,1]\n",
    "\n",
    "from scipy.stats import rankdata\n",
    "data.iloc[:233154,-1] = rankdata(is_test_Probs)\n",
    "bins = np.histogram(data.iloc[:233154,-1])[1][:-1]\n",
    "stratCol = np.digitize(data.iloc[:233154,-1], bins)\n",
    "x_train = data.iloc[:233154,:]\n",
    "x_test = data.iloc[233154:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runLGB(train_X, train_y, test_X, test_y=None, test_X2=None, dep=8, seed=0, data_leaf=200):\n",
    "    params = {}\n",
    "    params[\"objective\"] = \"binary\"\n",
    "    params['metric'] = 'auc'\n",
    "    params[\"max_depth\"] = dep\n",
    "    params[\"num_leaves\"] = 30\n",
    "    params[\"min_data_in_leaf\"] = data_leaf\n",
    "    params[\"learning_rate\"] = 0.01\n",
    "    params[\"bagging_fraction\"] = 0.8\n",
    "    params[\"feature_fraction\"] = 0.35\n",
    "    params[\"feature_fraction_seed\"] = seed\n",
    "    params[\"bagging_freq\"] = 1\n",
    "    params[\"bagging_seed\"] = seed\n",
    "    params[\"lambda_l2\"] = 5\n",
    "    params[\"lambda_l1\"] = 5\n",
    "    params[\"verbosity\"] = -1\n",
    "    num_rounds = 20000\n",
    "\n",
    "    plst = list(params.items())\n",
    "    lgtrain = lgb.Dataset(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        lgtest = lgb.Dataset(test_X, label=test_y)\n",
    "        model = lgb.train(params, lgtrain, num_rounds, valid_sets=[lgtest], early_stopping_rounds=200, verbose_eval=500)\n",
    "    else:\n",
    "        lgtest = lgb.DMatrix(test_X)\n",
    "        model = lgb.train(params, lgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n",
    "    pred_test_y2 = model.predict(test_X2, num_iteration=model.best_iteration)\n",
    "\n",
    "    loss = 0\n",
    "    if test_y is not None:\n",
    "        loss = metrics.roc_auc_score(test_y, pred_test_y)\n",
    "        print(loss)\n",
    "        return model, loss, pred_test_y, pred_test_y2\n",
    "    else:\n",
    "        return model, loss, pred_test_y, pred_test_y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building model..\")\n",
    "cv_scores = []\n",
    "pred_test_full = 0\n",
    "pred_train = np.zeros(train_X.shape[0])\n",
    "n_splits = 3\n",
    "#kf = model_selection.KFold(n_splits=n_splits, shuffle=True, random_state=7988)\n",
    "gkf = model_selection.GroupKFold(n_splits=n_splits)\n",
    "model_name = \"lgb\"\n",
    "for dev_index, val_index in gkf.split(train_X, train_df[\"loan_default\"].values, train_df[\"DisbursalMonth\"].values):\n",
    "    dev_X, val_X = train_X.iloc[dev_index,:], train_X.iloc[val_index,:]\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "\n",
    "    pred_val = 0\n",
    "    pred_test = 0\n",
    "    n_models = 0.\n",
    "\n",
    "    model, loss, pred_v, pred_t = runLGB(dev_X, dev_y, val_X, val_y, test_X, dep=8, seed=2019)\n",
    "    pred_val += pred_v\n",
    "    pred_test += pred_t\n",
    "    n_models += 1\n",
    "    \n",
    "    model, loss, pred_v, pred_t = runLGB(dev_X, dev_y, val_X, val_y, test_X, dep=7, data_leaf=100, seed=9873)\n",
    "    pred_val += pred_v\n",
    "    pred_test += pred_t\n",
    "    n_models += 1\n",
    "    \n",
    "    model, loss, pred_v, pred_t = runLGB(dev_X, dev_y, val_X, val_y, test_X, dep=9, data_leaf=150, seed=4568)\n",
    "    pred_val += pred_v\n",
    "    pred_test += pred_t\n",
    "    n_models += 1\n",
    "    \n",
    "    pred_val /= n_models\n",
    "    pred_test /= n_models\n",
    "    \n",
    "    loss = metrics.roc_auc_score(val_y, pred_val)\n",
    "        \n",
    "    pred_train[val_index] = pred_val\n",
    "    pred_test_full += pred_test / n_splits\n",
    "    cv_scores.append(loss)\n",
    "#     break\n",
    "print(np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame(test_df[[\"UniqueID\"]])\n",
    "sub_df[\"loan_default\"] = pred_test_full\n",
    "sub_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
